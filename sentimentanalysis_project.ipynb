{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22ce87c0",
   "metadata": {},
   "source": [
    "# sentiment analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f483fb6b",
   "metadata": {},
   "source": [
    "### 1.classification of text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d360764",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "import nltk \n",
    "import random #to shuffle the dataset that we have\n",
    "import pickle\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB,BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression,SGDClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "from nltk.classify import ClassifierI\n",
    "from statistics import mode\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "669eed8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#class for voting\n",
    "class VoteClassifier(ClassifierI):\n",
    "    def __init__(self, *classifiers):\n",
    "        self._classifiers = classifiers\n",
    "    def classify(self, features):\n",
    "        votes = []\n",
    "        for c in self._classifiers:\n",
    "            v = c.classify(features)\n",
    "            votes.append(v)\n",
    "        return mode(votes)\n",
    "    def confidence(self, features):\n",
    "        votes = []\n",
    "        for c in self._classifiers:\n",
    "            v = c.classify(features)\n",
    "            votes.append(v)\n",
    "\n",
    "        choice_votes = votes.count(mode(votes))\n",
    "        conf = choice_votes / len(votes)\n",
    "        return conf\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab953d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "short_pos = open(\"positive.txt\",\"r\").read()\n",
    "short_neg = open(\"negative.txt\",\"r\").read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54ff9e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = []\n",
    "documents = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2e7c81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  j is adject, r is adverb, and v is verb\n",
    "#allowed_word_types = [\"J\",\"R\",\"V\"]\n",
    "# allowed_word_types = [\"J\"]\n",
    "\n",
    "# for p in short_pos.split('\\n'):\n",
    "#     documents.append( (p, \"pos\") )\n",
    "#     words = word_tokenize(p)\n",
    "#     pos = nltk.pos_tag(words)\n",
    "#     for w in pos:\n",
    "#         if w[1][0] in allowed_word_types:\n",
    "#             all_words.append(w[0].lower())\n",
    "\n",
    "    \n",
    "# for p in short_neg.split('\\n'):\n",
    "#     documents.append( (p, \"neg\") )\n",
    "#     words = word_tokenize(p)\n",
    "#     pos = nltk.pos_tag(words)\n",
    "#     for w in pos:\n",
    "#         if w[1][0] in allowed_word_types:\n",
    "#             all_words.append(w[0].lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d14ea1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's pickle\n",
    "# save_documents = open(\"documents.pickle\",\"wb\")\n",
    "# pickle.dump(documents, save_documents)\n",
    "# save_documents.close()\n",
    "#read the file\n",
    "save_documents_f = open(\"documents.pickle\", \"rb\")\n",
    "documents = pickle.load(save_documents_f)\n",
    "save_documents_f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cca852e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = nltk.FreqDist(all_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3528084e",
   "metadata": {},
   "source": [
    "### 2.word as features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f3134c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#word_features = list(all_words.keys())[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29a91af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickling\n",
    "# save_word_features = open(\"word_features5k.pickle\",\"wb\")\n",
    "# pickle.dump(word_features, save_word_features)\n",
    "# save_word_features.close()\n",
    "#read the file\n",
    "save_word_f = open(\"word_features5k.pickle\", \"rb\")\n",
    "word_features = pickle.load(save_word_f)\n",
    "save_word_f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f01cb465",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for finding these words in our positive and negative docs\n",
    "def find_features(document):\n",
    "    words = word_tokenize(document)\n",
    "    features = {}\n",
    "    for w in word_features:\n",
    "        features[w] = (w in words)\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a261fa9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresets = [(find_features(rev), category) for (rev, category) in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e32240ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10664\n"
     ]
    }
   ],
   "source": [
    "random.shuffle(featuresets)\n",
    "print(len(featuresets))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2603c1d",
   "metadata": {},
   "source": [
    "### 3.Naive Bayes classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ca7e38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set that we'll train our classifier with\n",
    "training_set = featuresets[:10000]\n",
    "# set that we'll test against.\n",
    "testing_set =  featuresets[10000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b41c32d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training\n",
    "#classifier = nltk.NaiveBayesClassifier.train(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "52b55d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save Classifier with Pickle\n",
    "# save_classifier = open(\"naivebayes.pickle\",\"wb\")\n",
    "# pickle.dump(classifier, save_classifier)\n",
    "# save_classifier.close()\n",
    "#read the file\n",
    "classifier_f = open(\"naivebayes.pickle\", \"rb\")\n",
    "classifier = pickle.load(classifier_f)\n",
    "classifier_f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f0b14ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier accuracy percent: 85.99397590361446\n"
     ]
    }
   ],
   "source": [
    "print(\"Classifier accuracy percent:\",(nltk.classify.accuracy(classifier, testing_set))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "56bde4e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "              engrossing = True              pos : neg    =     20.4 : 1.0\n",
      "                 generic = True              neg : pos    =     16.9 : 1.0\n",
      "                mediocre = True              neg : pos    =     16.2 : 1.0\n",
      "                 routine = True              neg : pos    =     15.6 : 1.0\n",
      "                  boring = True              neg : pos    =     13.5 : 1.0\n",
      "                    flat = True              neg : pos    =     13.3 : 1.0\n",
      "               inventive = True              pos : neg    =     13.1 : 1.0\n",
      "                    warm = True              pos : neg    =     12.3 : 1.0\n",
      "               wonderful = True              pos : neg    =     11.9 : 1.0\n",
      "               realistic = True              pos : neg    =     11.1 : 1.0\n",
      "                mindless = True              neg : pos    =     10.9 : 1.0\n",
      "                   stale = True              neg : pos    =     10.9 : 1.0\n",
      "                  stupid = True              neg : pos    =     10.5 : 1.0\n",
      "                    dull = True              neg : pos    =     10.3 : 1.0\n",
      "                powerful = True              pos : neg    =     10.2 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf12f54",
   "metadata": {},
   "source": [
    "### 4.Scikit-Learn classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "782a4170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB accuracy percent: 84.63855421686746\n",
      "BernoulliNB_classifier accuracy percent: 84.1867469879518\n"
     ]
    }
   ],
   "source": [
    "# MNB_classifier = SklearnClassifier(MultinomialNB())\n",
    "# MNB_classifier.train(training_set)\n",
    "\n",
    "#Save Classifier with Pickle\n",
    "# save_classifier1 = open(\"MultinomialNB.pickle\",\"wb\")\n",
    "# pickle.dump(MNB_classifier, save_classifier1)\n",
    "# save_classifier1.close()\n",
    "#read the file\n",
    "classifier_f1 = open(\"MultinomialNB.pickle\", \"rb\")\n",
    "MNB_classifier = pickle.load(classifier_f1)\n",
    "classifier_f1.close()\n",
    "print(\"MultinomialNB accuracy percent:\",nltk.classify.accuracy(MNB_classifier, testing_set)*100)\n",
    "\n",
    "# BernoulliNB_classifier = SklearnClassifier(BernoulliNB())\n",
    "# BernoulliNB_classifier.train(training_set)\n",
    "\n",
    "#Save Classifier with Pickle\n",
    "# save_classifier2 = open(\"BernoulliNB.pickle\",\"wb\")\n",
    "# pickle.dump(BernoulliNB_classifier, save_classifier2)\n",
    "# save_classifier2.close()\n",
    "#read the file\n",
    "classifier_f2 = open(\"BernoulliNB.pickle\", \"rb\")\n",
    "BernoulliNB_classifier = pickle.load(classifier_f2)\n",
    "classifier_f2.close()\n",
    "print(\"BernoulliNB_classifier accuracy percent:\", (nltk.classify.accuracy(BernoulliNB_classifier, testing_set))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bb1d33e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression_classifier accuracy percent: 71.98795180722891\n",
      "SGDClassifier_classifier accuracy percent: 72.43975903614458\n",
      "LinearSVC_classifier accuracy percent: 71.98795180722891\n"
     ]
    }
   ],
   "source": [
    "# LogisticRegression_classifier = SklearnClassifier(LogisticRegression())\n",
    "# LogisticRegression_classifier.train(training_set)\n",
    "\n",
    "#Save Classifier with Pickle\n",
    "# save_classifier3 = open(\"LogisticRegression.pickle\",\"wb\")\n",
    "# pickle.dump(LogisticRegression_classifier, save_classifier3)\n",
    "# save_classifier3.close()\n",
    "#read the file\n",
    "classifier_f3 = open(\"LogisticRegression.pickle\", \"rb\")\n",
    "LogisticRegression_classifier = pickle.load(classifier_f3)\n",
    "classifier_f3.close()\n",
    "print(\"LogisticRegression_classifier accuracy percent:\", (nltk.classify.accuracy(LogisticRegression_classifier, testing_set))*100)\n",
    "\n",
    "# SGDClassifier_classifier = SklearnClassifier(SGDClassifier())\n",
    "# SGDClassifier_classifier.train(training_set)\n",
    "\n",
    "#Save Classifier with Pickle\n",
    "# save_classifier4 = open(\"SGDClassifier.pickle\",\"wb\")\n",
    "# pickle.dump(SGDClassifier_classifier, save_classifier4)\n",
    "# save_classifier4.close()\n",
    "#read the file\n",
    "classifier_f4 = open(\"SGDClassifier.pickle\", \"rb\")\n",
    "SGDClassifier_classifier = pickle.load(classifier_f4)\n",
    "classifier_f4.close()\n",
    "print(\"SGDClassifier_classifier accuracy percent:\", (nltk.classify.accuracy(SGDClassifier_classifier, testing_set))*100)\n",
    "\n",
    "\n",
    "# LinearSVC_classifier = SklearnClassifier(LinearSVC())\n",
    "# LinearSVC_classifier.train(training_set)\n",
    "\n",
    "#Save Classifier with Pickle\n",
    "# save_classifier5 = open(\"LinearSVC.pickle\",\"wb\")\n",
    "# pickle.dump(LinearSVC_classifier, save_classifier5)\n",
    "# save_classifier5.close()\n",
    "#read the file\n",
    "classifier_f5 = open(\"LinearSVC.pickle\", \"rb\")\n",
    "LinearSVC_classifier = pickle.load(classifier_f5)\n",
    "classifier_f5.close()\n",
    "print(\"LinearSVC_classifier accuracy percent:\", (nltk.classify.accuracy(LinearSVC_classifier, testing_set))*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83fdb873",
   "metadata": {},
   "source": [
    "### 5.choosing classifier with a vote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b6e50f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "voted_classifier accuracy percent: 84.03614457831326\n"
     ]
    }
   ],
   "source": [
    "voted_classifier = VoteClassifier(classifier,\n",
    "                                  LinearSVC_classifier,\n",
    "                                  MNB_classifier,\n",
    "                                  BernoulliNB_classifier,\n",
    "                                  LogisticRegression_classifier)\n",
    "\n",
    "print(\"voted_classifier accuracy percent:\", (nltk.classify.accuracy(voted_classifier, testing_set))*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2bbefb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment(text):\n",
    "    feats = find_features(text)\n",
    "    return voted_classifier.classify(feats),voted_classifier.confidence(feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b8d104e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('pos', 0.6)\n",
      "('neg', 1.0)\n"
     ]
    }
   ],
   "source": [
    "print(sentiment(\"I think the movie was good until thanos died\"))\n",
    "print(sentiment(\"This movie was utter junk. There were absolutely 0 action. I don't see what the point was at all. Horrible movie, 0/10\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "96593b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tweepy import Stream\n",
    "from tweepy import OAuthHandler\n",
    "from tweepy.streaming import StreamListener\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c10976f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#consumer key, consumer secret, access token, access secret.\n",
    "ckey=\"qkz1W6F4BSUc35Q9GHMo87K9f\"\n",
    "csecret=\"Jo1Mf9sBHkLISCKiB0ppeaNFyg1HTPFNgFdphTBeismdPmQiYe\"\n",
    "atoken=\"1429922353283272704-dSGw43QEbWRTxyfCNF2372ibO86GA8\"\n",
    "asecret=\"4PQD7qPD77dgtXkq54lxFxVgesiTKUwnu44doI1Y8tDEd\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4870417d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class listener(StreamListener):\n",
    "\n",
    "    def on_data(self, data):\n",
    "\n",
    "        all_data = json.loads(data)\n",
    "\n",
    "        tweet = all_data[\"text\"]\n",
    "        sentiment_value, confidence = sentiment(tweet)\n",
    "        print(tweet, sentiment_value, confidence)\n",
    "\n",
    "        if confidence*100 >= 80:\n",
    "            output = open(\"twitter-out.txt\",\"a\")\n",
    "            output.write(sentiment_value)\n",
    "            output.write('\\n')\n",
    "            output.close()\n",
    "\n",
    "        return True\n",
    "\n",
    "    def on_error(self, status):\n",
    "        print(status)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "78b42302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT @BrandonDavisBD: Doctor Strange in the Multiverse of Madness has the opportunity to be one of the biggest MCU movies, like Avengers leve… neg 1.0\n",
      "hrm\n",
      "it's not been that long ago that I've watched Awake. did not expect netflix to pull the same stunt twice oO (tr… https://t.co/3SmLmaSHJG neg 1.0\n",
      "RT @3Ralphie: Mine mom can not leave for MOVIES if I’m lay on her purse. https://t.co/1IGBTPLeBi neg 1.0\n",
      "@MagicalOverload I was 15- double date to movies with a friend. My date's mom drove and sat in another part of the theater. neg 1.0\n",
      "Michael Jackson’s Private Home Movies, 2003 https://t.co/oG95ZZaSNb pos 0.8\n",
      "@GrenjiGames irl i would also be a crime fighting superhero with spider powers fighting a lizard man in a sewer. th… https://t.co/oyq1NY0PI5 neg 1.0\n",
      "Γιατί λείπει η Lilly Wachowski από το #TheMatrix4; Η σταράτη απάντηση της ίδιας  #TheMatrixResurrections… https://t.co/puJ91DYj5y neg 1.0\n",
      "RT @RoyalEndeavour: Today's stream is also available on Odysee: https://t.co/z6xMTQyYyK pos 0.6\n",
      "RT @IrishCentral: Matt Damon recently recalled a fascinating Jack Nicholson moment from filming ​\"The Departed\" - what would Nicholson say… pos 1.0\n",
      "RT @_akabadazz: I want to go to the movies 🥺 neg 1.0\n",
      "@GenesisGarcia27 My boss refused to watch Parasite when I recommended it to her because 'subtitled movies are too h… https://t.co/oy5IEhUia3 pos 0.6\n",
      "RT @PoojaMedia: Ebuka: What’s the next thing after the show. \n",
      "\n",
      "JMK: God o. Let’s God continue to favour me. \n",
      "\n",
      "Sammie: Finish school. Enroll… neg 1.0\n",
      "RT @empiremagazine: Jake Gyllenhaal receives a desperate call for help in the teaser trailer for thriller remake #TheGuilty: https://t.co/X… neg 1.0\n",
      "@ZenOfDesign We Finnish watch most of our movies with subs. It is everyday thing to do.\n",
      "\n",
      "Kids' movies are dubbed. N… https://t.co/VfyvmQbv68 pos 1.0\n",
      "@Ockomet LGBTQ+\n",
      "Athletic\n",
      "Ambivert\n",
      "Soft\n",
      "Single\n",
      "Movies\n",
      "Innocent\n",
      "Speak My Mind\n",
      "Popular neg 1.0\n",
      "This indicates he's bored, this is a waste of his time, he needs an icecream, and then a nap. Poor, old senile, ven… https://t.co/tjZetAjNek neg 1.0\n",
      "RT @Lubchansky: a year ago this week i thought i died on an operating table. it’s cool that i lived but i’m disappointed that i wasn’t ther… neg 0.8\n",
      "@Laraber10978845 Yes.\n",
      "\n",
      "Nothing better rhan a good horror movie.\n",
      "\n",
      "Watch it late at night with the lights off.\n",
      "\n",
      "And w… https://t.co/hGFKwlzwNh neg 0.6\n",
      "Indeed.\n",
      "\n",
      "https://t.co/2w1r2cmpbZ neg 1.0\n",
      "RT @MarleeMatlin: You are the best, Arne!  Thank you! 🤟🏼🤟🏼 @sianheder @EmiliaJonesy @TroyKotsur @DanielNDurant @AppleTVPlus @MattDentler #C… pos 1.0\n",
      "RT @CaseyExplosion: I have a particular loathing for the way in which so many Asian movies were remade in the US, not just because they wer… neg 1.0\n",
      "RT @QWaIIyWest: I say this because when you listen to Matt Reeves talk about it, you can genuinely see his passion and he’s so clearly prou… pos 0.6\n",
      "@reservoirbunny @Kevin6363K @PrimeVideo My trifecta of those movies is The Jerk, Blazing Saddles, and Harlem Nights! 😂 neg 1.0\n",
      "@Cindy100k_ Movies or shows neg 1.0\n",
      "RT @Ambasca_1: All $STARS holders are invited to vote for movies that will be the first to be greenlit via blockchain .\n",
      "#Mogul $STARS #defi… pos 0.8\n",
      "RT @chyadosensei: Reminds me of how clueless the west is when something successful comes out of Asia. https://t.co/5WyVWTw96f neg 1.0\n",
      "It’s sad to hear that you’re gone. But I’ll always remember you, when you voiced Carl Fredricksen from Up! pos 0.8\n",
      "RT @PeterGilmoreArt: Remakes/Reboots incoming for Train to Busan, Interview with the Vampire, Salem's Lot, Dead Space, Skyrim and a whole b… neg 1.0\n",
      "#US #USA #VisitUS #California #Hollywood #LosAngeles #LA #VisitLA #VisitLosAngeles #CA #VisitCalifornia… https://t.co/C6uwEjzZ8w neg 1.0\n",
      "Imagining of there was discourse about like, The Gentlemen the same way people mine other movies for content neg 1.0\n",
      "I am going to once again rank all the mcu movies neg 1.0\n",
      "@compassion_is @Alyssa_Milano @POTUS HE BASED HIS BULL 💩 LIFE OFF OF MOVIES. GO RESEARCH EDUCATION IS KEY TO MAKING… https://t.co/iwhA03S4Vm neg 1.0\n",
      "Finally opened up my Bruce Lee Criterion set for movie 81/100 The Big Boss, Bruce's first movie. I've watched all o… https://t.co/KYJI1CAEhj pos 0.6\n",
      "RT @lokislawyer: @_victoriasavage @shelbyfier @FilmUpdates i only watch cringe movies through dylan is in trouble tbh neg 1.0\n",
      "Watching movies on a loosely goth related server was a mistake. \n",
      "\n",
      "Watch a movie about swallowing objects and anothe… https://t.co/kDueR4UjDZ neg 1.0\n",
      "hii im not new to #mlbtwt / #filmtwt but i wanted to try a new acc!! plz rt to help me find mutuals 😄 my fave shows… https://t.co/60MCemDwjW neg 1.0\n",
      "@tieflingkisser Because they were written like shit. Most of the fans don’t like any of the characters in this film… https://t.co/G5vHnSbcpt neg 1.0\n",
      "Just watch the original movie like a normal person??? what is the need for a remake?? Is it for the US industry to… https://t.co/HSGVffZmBz neg 1.0\n",
      "@fkdupinthecrib yeah we got blessed in 2019 man these movies are awesome pos 0.8\n",
      "@FrankKane11 I'm really not a fan of most movies. I seem to have a thing for Space Opera though. Which is one of the genres I like to write. neg 1.0\n",
      "@DCFanatic1991 They can't even do the characters right in the movies pos 0.6\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-d3973fa7f925>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtwitterStream\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStream\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mauth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlistener\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mtwitterStream\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrack\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"movies\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\tweepy\\streaming.py\u001b[0m in \u001b[0;36mfilter\u001b[1;34m(self, follow, track, is_async, locations, stall_warnings, languages, encoding, filter_level)\u001b[0m\n\u001b[0;32m    472\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'filter_level'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfilter_level\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    473\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'delimited'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'length'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 474\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_async\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    475\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    476\u001b[0m     def sitestream(self, follow, stall_warnings=False,\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\tweepy\\streaming.py\u001b[0m in \u001b[0;36m_start\u001b[1;34m(self, is_async)\u001b[0m\n\u001b[0;32m    387\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_thread\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    388\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 389\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    390\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    391\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mon_closed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\tweepy\\streaming.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    287\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msnooze_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msnooze_time_step\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    288\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistener\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_connect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 289\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_read_loop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    290\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTimeout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mssl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSSLError\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m                 \u001b[1;31m# This is still necessary, as a SSLError can actually be\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\tweepy\\streaming.py\u001b[0m in \u001b[0;36m_read_loop\u001b[1;34m(self, resp)\u001b[0m\n\u001b[0;32m    337\u001b[0m             \u001b[0mlength\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    338\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclosed\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 339\u001b[1;33m                 \u001b[0mline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_line\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    340\u001b[0m                 \u001b[0mstripped_line\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mline\u001b[0m \u001b[1;31m# line is sometimes None so we need to check here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mstripped_line\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\tweepy\\streaming.py\u001b[0m in \u001b[0;36mread_line\u001b[1;34m(self, sep)\u001b[0m\n\u001b[0;32m    198\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    199\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 200\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_buffer\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stream\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_chunk_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    201\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\urllib3\\response.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[0;32m    517\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m                 \u001b[0mcache_content\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 519\u001b[1;33m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mfp_closed\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34mb\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    520\u001b[0m                 if (\n\u001b[0;32m    521\u001b[0m                     \u001b[0mamt\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    453\u001b[0m             \u001b[1;31m# Amount is given, implement using readinto\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    454\u001b[0m             \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbytearray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 455\u001b[1;33m             \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    456\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mmemoryview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    457\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mreadinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    487\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchunked\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_readinto_chunked\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlength\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_readinto_chunked\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    582\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    583\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 584\u001b[1;33m                 \u001b[0mchunk_left\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_chunk_left\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    585\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mchunk_left\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    586\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mtotal_bytes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_get_chunk_left\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    550\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_safe_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# toss the CRLF at the end of the chunk\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 552\u001b[1;33m                 \u001b[0mchunk_left\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_read_next_chunk_size\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    553\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mIncompleteRead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mb''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_read_next_chunk_size\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    510\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_read_next_chunk_size\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    511\u001b[0m         \u001b[1;31m# Read the next chunk size from the file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 512\u001b[1;33m         \u001b[0mline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    513\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    514\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"chunk size\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    702\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    703\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 704\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    705\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    706\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1239\u001b[0m                   \u001b[1;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1240\u001b[0m                   self.__class__)\n\u001b[1;32m-> 1241\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1242\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1243\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\ssl.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1097\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1098\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1099\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1100\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1101\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "auth = OAuthHandler(ckey, csecret)\n",
    "auth.set_access_token(atoken, asecret)\n",
    "\n",
    "twitterStream = Stream(auth, listener())\n",
    "twitterStream.filter(track=[\"movies\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a674f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
